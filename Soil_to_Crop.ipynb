{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r'Soil_to_Crop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>EC</th>\n",
       "      <th>OC</th>\n",
       "      <th>Avail-P</th>\n",
       "      <th>Exch-K</th>\n",
       "      <th>Avail-Ca</th>\n",
       "      <th>Avail-Mg</th>\n",
       "      <th>Avail-S</th>\n",
       "      <th>Avail-Zn</th>\n",
       "      <th>Avail-B</th>\n",
       "      <th>Avail-Fe</th>\n",
       "      <th>Avail-Cu</th>\n",
       "      <th>Avail-Mn</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>Crop_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4088 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pH     EC     OC  Avail-P  Exch-K  Avail-Ca  Avail-Mg  Avail-S  \\\n",
       "0     False  False  False    False   False     False     False    False   \n",
       "1     False  False  False    False   False     False     False    False   \n",
       "2     False  False  False    False   False     False     False    False   \n",
       "3     False  False  False    False   False     False     False    False   \n",
       "4     False  False  False    False   False     False     False    False   \n",
       "...     ...    ...    ...      ...     ...       ...       ...      ...   \n",
       "4083  False  False  False    False   False     False     False    False   \n",
       "4084  False  False  False    False   False     False     False    False   \n",
       "4085  False  False  False    False   False     False     False    False   \n",
       "4086  False  False  False    False   False     False     False    False   \n",
       "4087  False  False  False    False   False     False     False    False   \n",
       "\n",
       "      Avail-Zn  Avail-B  Avail-Fe  Avail-Cu  Avail-Mn  Soil_type  Crop_type  \n",
       "0        False    False     False     False     False      False      False  \n",
       "1        False    False     False     False     False      False      False  \n",
       "2        False    False     False     False     False      False      False  \n",
       "3        False    False     False     False     False      False      False  \n",
       "4        False    False     False     False     False      False      False  \n",
       "...        ...      ...       ...       ...       ...        ...        ...  \n",
       "4083     False    False     False     False     False      False      False  \n",
       "4084     False    False     False     False     False      False      False  \n",
       "4085     False    False     False     False     False      False      False  \n",
       "4086     False    False     False     False     False      False      False  \n",
       "4087     False    False     False     False     False      False      False  \n",
       "\n",
       "[4088 rows x 15 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pH           float64\n",
       "EC           float64\n",
       "OC           float64\n",
       "Avail-P      float64\n",
       "Exch-K         int64\n",
       "Avail-Ca       int64\n",
       "Avail-Mg       int64\n",
       "Avail-S      float64\n",
       "Avail-Zn     float64\n",
       "Avail-B      float64\n",
       "Avail-Fe     float64\n",
       "Avail-Cu     float64\n",
       "Avail-Mn     float64\n",
       "Soil_type      int64\n",
       "Crop_type     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4088, 13)\n",
      "(4088,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 0:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2861, 13)\n",
      "(1227, 13)\n",
      "(2861,)\n",
      "(1227,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "sc.fit(X_test)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model is: 71.71964140179298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "print(\"Accuracy of Logistic Regression model is:\",\n",
    "metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 4 ... 4 4 1]\n",
      "The accuracy of the Random Forest classifier on training data is 1.00\n",
      "The accuracy of the Random Forest classifier on test data is 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create Random Forest object\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state=0)\n",
    "\n",
    "#Train model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "testlabel = random_forest.predict(X_test)\n",
    "print(testlabel)\n",
    "\n",
    "#Test model\n",
    "#random_forest.fit(X_test, y_test)\n",
    "\n",
    "print('The accuracy of the Random Forest classifier on training data is {:.2f}'.format(random_forest.score(X_train, y_train)))\n",
    "print('The accuracy of the Random Forest classifier on test data is {:.2f}'.format(random_forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(random_state=1, multi_class='multinomial', penalty='none', solver='newton-cg', max_iter=1000, dual=False).fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = model1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model is: 71.47514262428687\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression model is:\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decison Tree Classifier model is: 70.6601466992665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=500, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy of Decison Tree Classifier model is:\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:10:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7609075 , 0.76223776, 0.74475524, 0.76223776, 0.75      ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import cross_val_score for cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# score XGBClassifier\n",
    "cross_val_score(XGBClassifier(), X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.693815 (0.022811)\n",
      "RF: 0.769661 (0.031872)\n",
      "KNN: 0.682636 (0.026107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.667602 (0.031333)\n",
      "NB: 0.524999 (0.031508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.688574 (0.028730)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "#names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "#dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataset.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    plt.bar(name,cv_results)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Comparison of ML Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, precision_score, recall_score\n",
    "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model. RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    #svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "   #tree.ExtraTreeClassifier(),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\babby\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Train Accuracy</th>\n",
       "      <th>MLA Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MLA Name  MLA Train Accuracy  MLA Test Accuracy\n",
       "0            AdaBoostClassifier                0.66               0.67\n",
       "1             BaggingClassifier                0.99               0.71\n",
       "2          ExtraTreesClassifier                1.00               0.76\n",
       "3    GradientBoostingClassifier                0.87               0.74\n",
       "4        RandomForestClassifier                1.00               0.75\n",
       "5     GaussianProcessClassifier                1.00               0.03\n",
       "6          LogisticRegressionCV                0.73               0.71\n",
       "7   PassiveAggressiveClassifier                0.51               0.53\n",
       "8             RidgeClassifierCV                0.72               0.70\n",
       "9                 SGDClassifier                0.61               0.60\n",
       "10                   Perceptron                0.66               0.64\n",
       "11                  BernoulliNB                0.48               0.46\n",
       "12                   GaussianNB                0.53               0.50\n",
       "13         KNeighborsClassifier                0.78               0.68\n",
       "14                          SVC                0.69               0.68\n",
       "15                    LinearSVC                0.15               0.15\n",
       "16       DecisionTreeClassifier                1.00               0.65"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    \n",
    "    predicted = alg.fit(X_train, y_train).predict(X_test)\n",
    "    #fp, tp, th = roc_curve(y_test, predicted)\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(X_train, y_train), 2)\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(X_test, y_test), 2)\n",
    "    #MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted)\n",
    "    #MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted)\n",
    "    #MLA_compare.loc[row_index, 'MLA AUC'] = auc(fp, tp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    row_index += 1\n",
    "    \n",
    "#MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Type Prediction based on Soil Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[8.05, 0.13, 0.33, 3.08, 130, 2723, 322, 3.33, 0.32, 0.62, 6.56, 0.91, 8.96], Predicted=1\n"
     ]
    }
   ],
   "source": [
    "# define one new instance\n",
    "Xnew = [[8.05,0.13, 0.33, 3.08, 130, 2723, 322, 3.33, 0.32, 0.62, 6.56, 0.91, 8.96]]\n",
    "# make a prediction\n",
    "ynew = random_forest.predict(Xnew)\n",
    "predicted = ynew\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Prediction and Suggestions based on Soil Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil_Type_Predicted=[1]\n",
      "0                                             GROUNDNUT\n",
      "3                                             SUNFLOWER\n",
      "4                                                 PADDY\n",
      "5                                                TAMATO\n",
      "10                                               TOMATO\n",
      "                             ...                       \n",
      "3981                                            Topioca\n",
      "3985                                  COTTON (Sample-1)\n",
      "4075    Cashewnut, MANGO (Intercrop MAIZE And Seasamum)\n",
      "4084                                       Cashew+MAIZE\n",
      "4086                                            Brinjal\n",
      "Name: Crop_type, Length: 141, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Soil_Type_Predicted=%s\" % ynew)\n",
    "\n",
    "for Soil_Type_Predicted in dataset['Soil_type']:\n",
    "    break;\n",
    "print(dataset['Crop_type'].drop_duplicates())\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggested Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil_Type_Predicted=[1]\n",
      "['GROUNDNUT' 'SUNFLOWER' 'PADDY' 'TAMATO' 'TOMATO' 'Mulberry' 'Potatao'\n",
      " 'SWEETCORN' 'POTATO' 'CHILLIESES' 'MULBARRY' 'VEGETABLES' 'HORSEGRAM'\n",
      " 'BEANS' 'FLOWERS' 'CUCUMBER' 'KANDORA' 'MANGO' 'TURMERIC' 'YAM' 'BANANA'\n",
      " 'COTTON' 'RIDGEGUARD' 'CHILLIES' 'chill' 'BLACKSOILGRAM' 'MAIZE' 'PULSE'\n",
      " 'MAZI' 'Pigeonpea' 'JOWAR' 'Coriandam' 'Blacksoilgram' 'BENGALGRAM'\n",
      " 'Redsoilgram' 'PADDY,JOWAR' 'DHANIYA' 'JONNA, BENGALGRAM' 'TOBBACO'\n",
      " 'JONNA' 'Merappa ; BENGALGRAM' 'MOONGDAL' 'RICE' 'Cottan'\n",
      " 'Ground Nat,Cottan' 'Cottan,Ground Nat' 'Ground Nat' 'Cottan,'\n",
      " 'GROUNDNUT,Cottan' 'GROUNDNUT,COTTON' 'COTTON,GROUNDNUT' 'Citrus'\n",
      " 'Green Gram' 'Cowpea' 'Tobacco' 'Prawns' 'PADDY/G.gram' 'Cashew'\n",
      " 'BANANA/coconut' 'Coconut' 'PADDY Sugercane' 'Sugarcane '\n",
      " 'PADDY/ Sugarcane' 'Sugarcane' 'suger cane ' 'Ragi/Niger'\n",
      " 'MAIZE/PADDY/Rajma' 'MAIZE/Rajma' 'Rajma/MAIZE' 'PADDY/MAIZE/G.N'\n",
      " 'PADDY/MAIZE' 'Sesumum' 'Sesamum' 'MANGO(Inter Crop Ragi)'\n",
      " 'MANGO (Inter Crop Redsoil Gram And Ragi)' 'Cashew Nut' 'Oil Palm' 'Lime'\n",
      " 'Cane' 'Oil Palm+BANANA' 'Cabage' 'PAPAYA' 'CABBAGE' 'Dhavanam' 'BENDY'\n",
      " 'Anaar' 'Fodder Crops' 'Beera' 'Ragi' 'BAJRA' 'Turmaric'\n",
      " 'Light Blacksoil' 'Vegetable' 'Oniyan,Ground Nat' 'GROUNDNUT/GROUNDNUT'\n",
      " 'Grounat' 'Cottan ,Groundnat' 'Cottan,Castral' 'Castor'\n",
      " 'COTTON,Vegitable' 'GROUNDNUT,castor' 'GROUNDNUT ,CHILLIES'\n",
      " 'COTTON,castor' 'GROUNDNUT, COTTON' 'GROUNDNUT,JOWAR' 'GROUNDNUT ,COTTON'\n",
      " 'Clastor' 'Green gram' 'Cow pea' 'MAIZE/PADDY' 'coconut/BANANA' 'cashew'\n",
      " 'CHILLIES PAPAYA' 'MAIZE/Horti' 'COTTON/MAIZE' 'PADDY MAIZE' 'PADDY  '\n",
      " 'PADDY/Ragi' 'PADDY/GROUNDNUT' 'SUGER CANE ' 'MANGO(Intercrop Ragi,)'\n",
      " 'MANGO(Intercrop Ragi)' 'Mesta' 'Cashewnut' ' MAIZE'\n",
      " 'Coconut (Intercop MAIZE)' 'Cashew Raina' 'Eucalyptus' 'Onian'\n",
      " 'Sandysoil' 'Eucaliptus' 'Redsoil Gram' 'PADDY ' 'Topioca (Sample-2)'\n",
      " 'Topioca (Sample-1)' 'PADDY (Sample-2)' 'Topioca' 'COTTON (Sample-1)'\n",
      " 'Cashewnut, MANGO (Intercrop MAIZE And Seasamum)' 'Cashew+MAIZE'\n",
      " 'Brinjal']\n"
     ]
    }
   ],
   "source": [
    "print(\"Soil_Type_Predicted=%s\" % ynew)\n",
    "\n",
    "for Soil_Type_Predicted in dataset['Soil_type']:\n",
    "    break;\n",
    "print(dataset['Crop_type'].unique())\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
